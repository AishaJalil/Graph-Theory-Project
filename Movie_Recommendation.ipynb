import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split

# Read ratings file
ratings = pd.read_csv('r1.csv')

def get_top_recommendations(user_id, n=5):
    """Return the top N movie recommendations for the given user."""
    top_movies = user_final_ratings.loc[user_id].sort_values(ascending=False).head(n)
    return top_movies

# Handle duplicates: Aggregate duplicates by averaging the ratings
ratings = ratings.groupby(['userId', 'movieId'], as_index=False)['rating'].mean()

# Train-test split
X_train, X_test = train_test_split(ratings, test_size=0.30, random_state=42)

# Pivot ratings into movie features for training data
user_data_train = X_train.pivot(index='userId', columns='movieId', values='rating').fillna(0)

# Pivot ratings into movie features for test data
user_data_test = X_test.pivot(index='userId', columns='movieId', values='rating').fillna(0)

# Create dummy train dataset for training data
dummy_train = X_train.copy()
dummy_train['rating'] = dummy_train['rating'].apply(lambda x: 0 if x > 0 else 1)
dummy_train = dummy_train.pivot(index='userId', columns='movieId', values='rating').fillna(1)

# Create dummy test dataset for test data
dummy_test = X_test.copy()
dummy_test['rating'] = dummy_test['rating'].apply(lambda x: 0 if x > 0 else 1)
dummy_test = dummy_test.pivot(index='userId', columns='movieId', values='rating').fillna(1)

# User-User Similarity matrix using Cosine similarity (train data)
user_similarity = cosine_similarity(user_data_train)
user_similarity[np.isnan(user_similarity)] = 0

# Predicted ratings for each user (train data)
user_predicted_ratings = np.dot(user_similarity, user_data_train)

# We do not want to recommend the same movie the user has already watched
user_final_ratings = np.multiply(user_predicted_ratings, dummy_train)

# Convert to DataFrame for better readability (train data)
user_final_ratings = pd.DataFrame(user_final_ratings, index=user_data_train.index, columns=user_data_train.columns)


# Get input from the user
user_id_input = int(input("Enter User ID to recommend movies for: "))

# Get top 5 recommendations
top_5_recommendations = get_top_recommendations(user_id_input)
print("\nTop 5 Movie Recommendations for User", user_id_input)
print(top_5_recommendations)



def create_bipartite_graph(data, user_final_ratings):
    """Create a bipartite graph of users and movies based on given data."""
    B = nx.Graph()
    for user in user_final_ratings.index:
        for movie in user_final_ratings.columns:
            if user_final_ratings.loc[user, movie] > 0:
                rating = user_final_ratings.loc[user, movie]
                B.add_edge(f'user_{user}', f'movie_{movie}', weight=rating)
    return B


def create_user_based_projection(B):
    """Create a user-based projected bipartite graph."""
    users = [n for n in B.nodes if 'user_' in n]
    projected_graph = nx.Graph()

    for i, user1 in enumerate(users):
        for user2 in users[i + 1:]:
            common_movies = nx.common_neighbors(B, user1, user2)
            weight = sum(B[user1][movie]['weight'] * B[user2][movie]['weight'] for movie in common_movies)
            if weight > 0:
                projected_graph.add_edge(user1, user2, weight=weight)

    return projected_graph


def create_similarity_bipartite_graph(similarity_matrix, user_ids, threshold=0.1):
    """
    Create a bipartite graph where users in one set are connected to similar users in the other set.

    Parameters:
    - similarity_matrix (2D array): User similarity matrix.
    - user_ids (list): List of user IDs corresponding to the rows/columns of the similarity matrix.
    - threshold (float): Minimum similarity score to include an edge.
    Returns:
    - nx.Graph: Bipartite graph with users in two sets connected by similarity scores.
    """
    # Initialize an empty graph
    B = nx.Graph()
    
    # Add nodes for the two sets (users and their similar counterparts)
    user_nodes = [f"user_{user}" for user in user_ids]
    B.add_nodes_from(user_nodes, bipartite=0)  # Set 0
    
    similar_user_nodes = [f"similar_user_{user}" for user in user_ids]
    B.add_nodes_from(similar_user_nodes, bipartite=1)  # Set 1
    
    # Add edges based on the similarity matrix
    for i, user1 in enumerate(user_ids):
        for j, user2 in enumerate(user_ids):
            if i != j:  # Avoid self-loops
                weight = similarity_matrix[i][j]
                if weight > threshold:  # Add edge only if similarity > threshold
                    B.add_edge(f"user_{user1}", f"similar_user_{user2}", weight=weight)
    
    return B


# Create the bipartite graph for similarity
user_ids = user_data_train.index.tolist()
threshold = 0.2  # Set a threshold for similarity to filter edges
bipartite_graph = create_similarity_bipartite_graph(user_similarity, user_ids, threshold)

# Define positions for bipartite layout
pos = nx.drawing.layout.bipartite_layout(bipartite_graph, [f"user_{user}" for user in user_ids])

# Plot the bipartite graph for user similarity
plt.figure(figsize=(16, 10))
nx.draw(
    bipartite_graph, pos, with_labels=True, node_size=800, 
    font_size=10, node_color="skyblue", edge_color="gray"
)
edge_labels = nx.get_edge_attributes(bipartite_graph, "weight")
nx.draw_networkx_edge_labels(bipartite_graph, pos, edge_labels=edge_labels)
plt.title("Bipartite Graph of Users and Similar Users Based on Similarity")
plt.show()


# Generate top 5 recommendations for all users automatically
top_n = 5  # Top N recommendations
recommendations = {}

for user_id in user_final_ratings.index:
    recommendations[user_id] = get_top_recommendations(user_id, n=top_n)

# Create bipartite graph for top recommendations
B_recommendations = create_bipartite_graph(ratings, user_final_ratings)

# Define positions for bipartite layout (recommendations data)
users_recommendations = [f"user_{user}" for user in user_final_ratings.index]
movies_recommendations = [f"movie_{movie}" for movie in user_final_ratings.columns]
m_rec, n_rec = len(users_recommendations), len(movies_recommendations)

pos_rec = {}
pos_rec.update((user, (i, 1)) for i, user in enumerate(users_recommendations))  # Position users on top
pos_rec.update((movie, (i, 0)) for i, movie in enumerate(movies_recommendations))  # Position movies at the bottom

# Plot the bipartite graph for top recommendations
plt.figure(figsize=(20, 8))
nx.draw(B_recommendations, pos_rec, with_labels=True, node_size=600, width=0.6, font_size=10, node_color='lightseagreen', edge_color='gray')
edge_labels_rec = nx.get_edge_attributes(B_recommendations, 'weight')
nx.draw_networkx_edge_labels(B_recommendations, pos=pos_rec, edge_labels=edge_labels_rec)
plt.title("User-Movie Bipartite Graph for Top Recommendations (Predicted Ratings)")
plt.show()

# Create and plot the bipartite graph for training data
B_train = create_bipartite_graph(X_train, user_data_train)

# Define positions for bipartite layout (training data)
users_train = [f"user_{user}" for user in user_final_ratings.index]
movies_train = [f"movie_{movie}" for movie in user_final_ratings.columns]
m_train, n_train = len(users_train), len(movies_train)

pos_train = {}
pos_train.update((user, (i, 1)) for i, user in enumerate(users_train))  # Position users on top
pos_train.update((movie, (i, 0)) for i, movie in enumerate(movies_train))  # Position movies at the bottom

# Plot the bipartite graph for training data
plt.figure(figsize=(20, 8))
nx.draw(B_train, pos_train, with_labels=True, node_size=600, width=0.6, font_size=10, node_color='lightblue', edge_color='gray')
edge_labels_train = nx.get_edge_attributes(B_train, 'weight')
nx.draw_networkx_edge_labels(B_train, pos=pos_train, edge_labels=edge_labels_train)
plt.title("User-Movie Bipartite Graph for Training Data with Ratings as Edge Weights")
plt.show()

# Create and plot the bipartite graph for test data using user_data_train
B_test = create_bipartite_graph(X_test, user_data_test)

# Define positions for bipartite layout (test data)
users_test = [f"user_{user}" for user in X_test['userId'].unique()]
movies_test = [f"movie_{movie}" for movie in X_test['movieId'].unique()]
m_test, n_test = len(users_test), len(movies_test)

pos_test = {}
pos_test.update((user, (i, 1)) for i, user in enumerate(users_test))  # Position users on top
pos_test.update((movie, (i, 0)) for i, movie in enumerate(movies_test))  # Position movies at the bottom

# Plot the bipartite graph for test data
plt.figure(figsize=(20, 8))
nx.draw(B_test, pos_test, with_labels=True, node_size=600, width=0.6, font_size=10, node_color='lightcoral', edge_color='gray')
edge_labels_test = nx.get_edge_attributes(B_test, 'weight')
nx.draw_networkx_edge_labels(B_test, pos=pos_test, edge_labels=edge_labels_test)
plt.title("User-Movie Bipartite Graph for Test Data")
plt.show()



# Evaluation

# Compute similarity matrix for test users
test_user_features = X_test.pivot(index='userId', columns='movieId', values='rating').fillna(0)
test_user_similarity = cosine_similarity(test_user_features)
test_user_similarity[np.isnan(test_user_similarity)] = 0

print(test_user_similarity)
print("- " * 10)
print(test_user_similarity.shape)

# Predicted ratings for test data
user_predicted_ratings_test = np.dot(test_user_similarity, test_user_features)


test_user_final_rating = np.multiply(user_predicted_ratings_test, dummy_test)
test_user_final_rating.head()

from sklearn.preprocessing import MinMaxScaler

# Normalize predicted ratings between 0.5 and 5
scaler = MinMaxScaler(feature_range=(0.5, 5))
X = test_user_final_rating.copy()
X[X == 0] = np.nan  # Ignore zero values for normalization
pred = pd.DataFrame(
    scaler.fit_transform(X.fillna(0)),
    index=test_user_final_rating.index,
    columns=test_user_final_rating.columns,
).fillna(0)

print(pred)

# Total non-NaN values
total_non_nan = np.count_nonzero(~np.isnan(pred))
print(f"Total non-NaN values: {total_non_nan}")

# Actual test ratings
test = test_user_features
test.head()

# RMSE Score
diff_sqr_matrix = (test - pred) ** 2
sum_of_squares_err = diff_sqr_matrix.sum().sum()
rmse = np.sqrt(sum_of_squares_err / total_non_nan)
print(f"RMSE: {rmse}")



# Mean Absolute Error (MAE)
mae = np.abs(pred - test).sum().sum() / total_non_nan
print(f"MAE: {mae}")
